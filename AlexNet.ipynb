{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjVO/K0LkZ8nUvJ63O37c+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imshiv-10/CNN-ConvNET5/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "KIyj8SBdhFGb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p_eE759xgnbX"
      },
      "outputs": [],
      "source": [
        "# define pytorch device - useful for device-agnostic execution\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkWcrI5MhI7Y",
        "outputId": "002d4708-eae5-4d94-f8fc-0bd8969ce968"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model parameters\n",
        "\n",
        "NUM_EPOCHS = 90  # original paper\n",
        "BATCH_SIZE = 128\n",
        "MOMENTUM = 0.9\n",
        "LR_DECAY = 0.0005\n",
        "LR_INIT = 0.01\n",
        "IMAGE_DIM = 224  # In original paper mentioned 224*224 pixels\n",
        "NUM_CLASSES = 1000  # 1000 classes for imagenet 2012 dataset\n",
        "DEVICE_IDS = [0, 1, 2, 3]  # GPUs to use\n",
        "\n",
        "# modify this to point to your data directory\n",
        "\n",
        "INPUT_ROOT_DIR = 'alexnet_data_in'\n",
        "TRAIN_IMG_DIR = 'alexnet_data_in/imagenet'\n",
        "OUTPUT_DIR = 'alexnet_data_out'\n",
        "LOG_DIR = OUTPUT_DIR + '/tblogs'  # tensorboard logs\n",
        "CHECKPOINT_DIR = OUTPUT_DIR + '/models'  # model checkpoints"
      ],
      "metadata": {
        "id": "dAG12kVJhK6R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make checkpoint path directory\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Xqi870Mnhfgt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Vz7_oiKSh7Vc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network model consisting of layers propsed by AlexNet paper.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=1000):\n",
        "        \"\"\"\n",
        "        Define and allocate layers for this neural net.\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): number of classes to predict with this model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # input size should be : (b x 3 x 224 x 224)\n",
        "        # The image in the original paper states that width and height are 224 pixels, but\n",
        "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  # (b x 96 x 55 x 55)\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
        "            nn.Conv2d(96, 256, 5, padding=2),  # (b x 256 x 27 x 27)\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
        "            nn.Conv2d(256, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 384, 3, padding=1),  # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 256, 3, padding=1),  # (b x 256 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
        "        )\n",
        "        # classifier is just a name for linear layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes),\n",
        "        )\n",
        "        self.init_bias()  # initialize bias\n",
        "\n",
        "    def init_bias(self):\n",
        "        for layer in self.net:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
        "        nn.init.constant_(self.net[4].bias, 1)\n",
        "        nn.init.constant_(self.net[10].bias, 1)\n",
        "        nn.init.constant_(self.net[12].bias, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Pass the input through the net.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): input tensor\n",
        "\n",
        "        Returns:\n",
        "            output (Tensor): output tensor\n",
        "        \"\"\"\n",
        "        x = self.net(x)\n",
        "        x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "W7sBnKO_hpjR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device_ids = [0, 1]\n",
        "if not all(0 <= device_id < torch.cuda.device_count() for device_id in device_ids):\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS4K1-UGmOI-",
        "outputId": "f0b2c9a5-4dd1-4fb3-b6cf-e4d804e68ac7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = torch.initial_seed()\n",
        "print('Used seed : {}'.format(seed))\n",
        "\n",
        "# create model\n",
        "alexnet = AlexNet(num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "print(alexnet)\n",
        "print('AlexNet created')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23ZFFACploXn",
        "outputId": "3a91f5a1-46b1-43a7-ae4b-56ade05231a4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used seed : 14122963979254700982\n",
            "AlexNet(\n",
            "  (net): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (5): ReLU()\n",
            "    (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
            "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU()\n",
            "    (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=True)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.5, inplace=True)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "AlexNet created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n"
      ],
      "metadata": {
        "id": "_U3KOAIdnWk7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # create dataset and data loader\n",
        "dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n",
        "        # transforms.RandomResizedCrop(IMAGE_DIM, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "        transforms.CenterCrop(IMAGE_DIM),\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]))\n",
        "print('Dataset created')\n",
        "dataloader = data.DataLoader(\n",
        "        dataset,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=8,\n",
        "        drop_last=True,\n",
        "        batch_size=BATCH_SIZE)\n",
        "print('Dataloader created')"
      ],
      "metadata": {
        "id": "csMwim92m0zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mP5oPI0Pnt7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}